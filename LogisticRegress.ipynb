{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LogisticRegressionWithMomentum:\n",
    "    def __init__(self, learning_rate=0.01, epochs=10000, reg_lambda=0.01, momentum=0.9, tol=1e-4, patience=10, min_loss_threshold=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.momentum = momentum\n",
    "        self.tol = tol  # Ngưỡng cải thiện loss\n",
    "        self.patience = patience  # Số epoch liên tiếp không cải thiện trước khi dừng\n",
    "        self.min_loss_threshold = min_loss_threshold  # Ngưỡng tối thiểu của loss để dừng\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.velocity_w = None\n",
    "        self.velocity_b = None\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def compute_loss(self, y, y_predicted):\n",
    "        num_samples = len(y)\n",
    "        y_predicted = np.clip(y_predicted, 1e-15, 1 - 1e-15)\n",
    "        loss = (-1 / num_samples) * np.sum(y * np.log(y_predicted + 1e-15) + (1 - y) * np.log(1 - y_predicted + 1e-15))\n",
    "        clipped_weights = np.clip(self.weights, -1e5, 1e5)  # Giới hạn giá trị trọng số\n",
    "        reg_loss = (self.reg_lambda / (2 * num_samples)) * np.sum(clipped_weights ** 2)\n",
    "        return loss + reg_loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        self.velocity_w = np.zeros(num_features)\n",
    "        self.velocity_b = 0\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "            loss = self.compute_loss(y, y_predicted)\n",
    "            if loss < best_loss - self.tol:\n",
    "                best_loss = loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            if patience_counter >= self.patience and best_loss < self.min_loss_threshold:\n",
    "                print(f\"Early stopping at epoch {epoch}: loss = {best_loss}\")\n",
    "                break\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y)) + (self.reg_lambda * self.weights) / num_samples\n",
    "            db = (1 / num_samples) * np.sum((y_predicted - y))\n",
    "            self.velocity_w = self.momentum * self.velocity_w - self.learning_rate * dw\n",
    "            self.velocity_b = self.momentum * self.velocity_b - self.learning_rate * db\n",
    "            self.weights += self.velocity_w\n",
    "            self.bias += self.velocity_b\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        return [1 if i > 0.5 else 0 for i in y_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col=[col for col in data.columns if data[col].dtype in ['float64','int64']]\n",
    "cat_col=[col for col in data.columns if data[col].dtype =='object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_one= LabelEncoder()\n",
    "for col in cat_col:\n",
    "    data[col]=cat_one.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "sns.heatmap(data.corr(),annot=True,fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macor= data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr_columns = [\n",
    "    col for col in data.columns\n",
    "    if all(abs(macor[col]['loan_status']) < 0.015 for other_col in data.columns if col != other_col)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=low_corr_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col=[col for col in data.columns if data[col].dtype in ['float64','int64']]\n",
    "cat_col=[col for col in data.columns if data[col].dtype =='object']\n",
    "num_col.remove('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(35, 20))\n",
    "\n",
    "# Vẽ boxplot cho từng cột\n",
    "for i, col in enumerate(data.columns):\n",
    "    row = i // 5\n",
    "    col_idx = i % 5\n",
    "    sns.boxplot(y=data[col], ax=axes[row, col_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_col:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 0.3 * IQR\n",
    "    upper_bound = Q3 + 0.3 * IQR\n",
    "\n",
    "\n",
    "    data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "    def delete_outliers(data, column, m=3):\n",
    "        mean = np.mean(data[column])\n",
    "        std_dev = np.std(data[column])\n",
    "        lower_bound = mean - m * std_dev\n",
    "        upper_bound = mean + m * std_dev\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    # Set a standard deviation threshold multiplied by m\n",
    "    m = 3\n",
    "\n",
    "    # Calculate limits for each variable and remove outliers\n",
    "    for column in num_col:\n",
    "        lower_bound, upper_bound = delete_outliers(data, column, m)\n",
    "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "    #Reset the index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(35, 20))\n",
    "\n",
    "# Vẽ boxplot cho từng cột\n",
    "for i, col in enumerate(data.columns):\n",
    "    row = i // 5\n",
    "    col_idx = i % 5\n",
    "    sns.boxplot(y=data[col], ax=axes[row, col_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns='loan_status')\n",
    "Y= data['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X, Y = smote.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCV= LogisticRegressionWithMomentum(epochs=100000)\n",
    "modelCV.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col=[col for col in data2.columns if data2[col].dtype in ['float64','int64']]\n",
    "cat_col=[col for col in data2.columns if data2[col].dtype =='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_one= LabelEncoder()\n",
    "for col in cat_col:\n",
    "    data2[col]=cat_one.fit_transform(data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(columns=low_corr_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col=[col for col in data2.columns if data2[col].dtype in ['float64','int64']]\n",
    "cat_col=[col for col in data2.columns if data2[col].dtype =='object']\n",
    "num_col.remove('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=data2.drop(columns='loan_status')\n",
    "Y2= data2['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = scaler.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelCV.predict(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(Y2, predictions))\n",
    "print(classification_report(Y2,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
